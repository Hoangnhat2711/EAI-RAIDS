# ğŸš€ EAI-RAIDS: Enterprise Responsible AI Framework

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Research](https://img.shields.io/badge/Research-Advanced-green.svg)]()

> **Framework AI CÃ³ TrÃ¡ch Nhiá»‡m ToÃ n Diá»‡n** - Production-Ready MLOps Solution vá»›i TÃ­nh nÄƒng NghiÃªn cá»©u TiÃªn tiáº¿n

Framework nÃ y cung cáº¥p má»™t há»‡ thá»‘ng hoÃ n chá»‰nh Ä‘á»ƒ phÃ¡t triá»ƒn, triá»ƒn khai vÃ  giÃ¡m sÃ¡t cÃ¡c há»‡ thá»‘ng AI cÃ³ trÃ¡ch nhiá»‡m, Ä‘áº£m báº£o **Fairness, Transparency, Privacy, Accountability, Explainability vÃ  Robustness**.

---

## âœ¨ Äiá»ƒm Ná»•i Báº­t

### ğŸ¯ **Tá»± Äá»™ng HÃ³a MLOps**
- âœ… **Mitigation Engine**: Tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  xá»­ lÃ½ bias/drift
- âœ… **Multi-Backend Audit Logging**: PostgreSQL, Elasticsearch, AWS CloudWatch, Azure Monitor, GCP
- âœ… **Intelligent Alert Manager**: Email, Slack, Webhook, SMS notifications
- âœ… **Auto-Retraining**: PhÃ¡t hiá»‡n drift vÃ  khuyáº¿n nghá»‹ retrain

### ğŸ”¬ **NghiÃªn Cá»©u TiÃªn Tiáº¿n**
- âœ… **Adversarial Robustness**: FGSM, PGD, DeepFool attacks + Adversarial Training
- âœ… **Advanced Fairness**: Demographic Parity, Equalized Odds, Disparate Impact
- âœ… **Causal Explainability**: KhÃ´ng chá»‰ correlation mÃ  cÃ²n causation
- âœ… **Differential Privacy**: DP-SGD cho Deep Learning

### ğŸ”§ **TÃ­ch Há»£p Linh Hoáº¡t**
- âœ… **Framework Agnostic**: Sklearn, PyTorch, TensorFlow adapters
- âœ… **Production-Ready**: Enterprise logging, monitoring, alerting
- âœ… **Scalable**: Cloud-native architecture

---

## ğŸ“‹ Má»¥c Lá»¥c

1. [CÃ i Äáº·t](#cÃ i-Ä‘áº·t)
2. [Quick Start](#quick-start)
3. [Kiáº¿n TrÃºc](#kiáº¿n-trÃºc)
4. [TÃ­nh NÄƒng Chi Tiáº¿t](#tÃ­nh-nÄƒng-chi-tiáº¿t)
5. [Advanced Usage](#advanced-usage)
6. [Examples](#examples)
7. [Research Papers](#research-papers)

---

## ğŸ”§ CÃ i Äáº·t

### Basic Installation

```bash
git clone https://github.com/Hoangnhat2711/EAI-RAIDSs.git
cd EAI-RAIDSs
pip install -r requirements.txt
```

### Full Installation (vá»›i táº¥t cáº£ tÃ­nh nÄƒng)

```bash
# Core + Deep Learning
pip install torch tensorflow

# Enterprise Logging
pip install psycopg2-binary elasticsearch boto3

# Advanced Features
pip install imbalanced-learn shap lime fairlearn
```

---

## ğŸš€ Quick Start

```python
from core.responsible_ai import ResponsibleAI
from core.model_wrapper import ResponsibleModelWrapper
from core.mitigation_engine import MitigationEngine
from sklearn.ensemble import RandomForestClassifier

# 1. Khá»Ÿi táº¡o framework
rai = ResponsibleAI(config_path='config.yaml')

# 2. Tá»± Ä‘á»™ng xá»­ lÃ½ bias
mitigation_engine = MitigationEngine(rai)
X_clean, y_clean, report = mitigation_engine.analyze_and_mitigate_bias(
    X_train, y_train, sensitive_features
)

# 3. Train vá»›i responsible wrapper
model = RandomForestClassifier()
responsible_model = ResponsibleModelWrapper(model, rai)
responsible_model.fit(X_clean, y_clean, sensitive_features=sensitive_features)

# 4. Predict vÃ  Ä‘Ã¡nh giÃ¡
predictions = responsible_model.predict(X_test)
fairness_report = responsible_model.evaluate_fairness(
    X_test, y_test, predictions, sensitive_features
)

# 5. Generate report
print(responsible_model.generate_responsibility_report(X_test, y_test))
```

---

## ğŸ—ï¸ Kiáº¿n TrÃºc

```
EAI-RAIDS/
â”œâ”€â”€ core/                           # Core framework
â”‚   â”œâ”€â”€ responsible_ai.py          # Main framework class
â”‚   â”œâ”€â”€ model_wrapper.py           # Responsible model wrapper
â”‚   â”œâ”€â”€ validator.py               # Compliance validator
â”‚   â”œâ”€â”€ mitigation_engine.py       # ğŸ†• Auto bias/drift mitigation
â”‚   â”œâ”€â”€ alert_manager.py           # ğŸ†• Intelligent alerting
â”‚   â””â”€â”€ adapters/                  # ğŸ†• Framework adapters
â”‚       â”œâ”€â”€ sklearn_adapter.py
â”‚       â”œâ”€â”€ pytorch_adapter.py
â”‚       â””â”€â”€ tensorflow_adapter.py
â”‚
â”œâ”€â”€ fairness/                      # Fairness & Bias
â”‚   â”œâ”€â”€ metrics.py                 # Fairness metrics
â”‚   â””â”€â”€ bias_detector.py           # Bias detection
â”‚
â”œâ”€â”€ explainability/                # Explainability
â”‚   â”œâ”€â”€ shap_explainer.py          # SHAP explanations
â”‚   â”œâ”€â”€ lime_explainer.py          # LIME explanations
â”‚   â””â”€â”€ causal_explainer.py        # ğŸ†• Causal analysis
â”‚
â”œâ”€â”€ privacy/                       # Privacy Protection
â”‚   â”œâ”€â”€ differential_privacy.py    # Differential privacy
â”‚   â”œâ”€â”€ anonymization.py           # Data anonymization
â”‚   â””â”€â”€ dp_sgd.py                  # ğŸ†• DP-SGD for DL
â”‚
â”œâ”€â”€ robustness/                    # ğŸ†• Adversarial Robustness
â”‚   â”œâ”€â”€ attack_generator.py        # FGSM, PGD, DeepFool
â”‚   â””â”€â”€ defense_trainer.py         # Adversarial training
â”‚
â”œâ”€â”€ audit/                         # Audit & Logging
â”‚   â”œâ”€â”€ logger.py                  # Audit logger
â”‚   â”œâ”€â”€ reporter.py                # Report generator
â”‚   â””â”€â”€ handlers/                  # ğŸ†• Multi-backend handlers
â”‚       â”œâ”€â”€ file_handler.py
â”‚       â”œâ”€â”€ postgres_handler.py
â”‚       â”œâ”€â”€ elasticsearch_handler.py
â”‚       â””â”€â”€ cloud_handler.py
â”‚
â”œâ”€â”€ monitoring/                    # Monitoring
â”‚   â””â”€â”€ drift_detector.py          # Drift detection
â”‚
â””â”€â”€ examples/                      # Examples
    â”œâ”€â”€ demo.py                    # Basic demo
    â””â”€â”€ advanced_demo.py           # ğŸ†• Advanced features
```

---

## ğŸ¯ TÃ­nh NÄƒng Chi Tiáº¿t

### 1. **Mitigation Engine** ğŸ”§

Tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  xá»­ lÃ½ cÃ¡c váº¥n Ä‘á»:

```python
from core.mitigation_engine import MitigationEngine

engine = MitigationEngine(rai)

# Tá»± Ä‘á»™ng xá»­ lÃ½ class imbalance
X_balanced, y_balanced, report = engine.analyze_and_mitigate_bias(
    X, y, sensitive_features
)

# TÃ­nh sample weights
weights = engine.compute_sample_weights(y, sensitive_features)

# Post-process predictions cho fairness
predictions_fair = engine.postprocess_predictions(
    predictions, sensitive_features, 
    fairness_constraint='demographic_parity'
)
```

**Techniques:**
- Class Reweighting
- SMOTE Oversampling
- Representation Balancing
- Fairness-constrained Post-processing

---

### 2. **Adversarial Robustness** ğŸ›¡ï¸

Test vÃ  defense against adversarial attacks:

```python
from robustness.attack_generator import AttackGenerator
from robustness.defense_trainer import DefenseTrainer

# Generate attacks
attack_gen = AttackGenerator(model)
X_adv, report = attack_gen.fgsm_attack(X, y, epsilon=0.3)
X_adv, report = attack_gen.pgd_attack(X, y, epsilon=0.3, num_iter=40)

# Comprehensive robustness evaluation
robustness = attack_gen.evaluate_robustness(X_test, y_test)

# Adversarial training
defense = DefenseTrainer(model, attack_gen)
defense.adversarial_training(
    X_train, y_train,
    attack_config={'attack_type': 'pgd', 'epsilon': 0.3},
    ratio=0.5
)
```

**Attacks Supported:**
- FGSM (Fast Gradient Sign Method)
- PGD (Projected Gradient Descent)
- DeepFool
- C&W (Carlini & Wagner)

---

### 3. **Multi-Backend Audit Logging** ğŸ“

Enterprise-grade logging vá»›i multiple backends:

```python
from audit.logger import AuditLogger
from audit.handlers import PostgreSQLHandler, ElasticsearchHandler

# Multiple handlers
handlers = [
    FileLogHandler({'log_dir': 'logs'}),
    PostgreSQLHandler({
        'host': 'localhost',
        'database': 'audit_db',
        'user': 'admin'
    }),
    ElasticsearchHandler({
        'hosts': ['http://localhost:9200'],
        'index_name': 'ai-audit'
    })
]

logger = AuditLogger(handlers=handlers)

# Logs automatically written to all backends
logger.log_prediction(X, predictions, model_info={'version': '1.0'})
```

**Supported Backends:**
- File (JSONL)
- PostgreSQL
- Elasticsearch
- AWS CloudWatch
- Azure Monitor
- GCP Cloud Logging

---

### 4. **Alert Manager** ğŸš¨

Intelligent alerting system:

```python
from core.alert_manager import AlertManager, AlertLevel

alert_manager = AlertManager({
    'channels': {
        'console': {'enabled': True},
        'email': {
            'enabled': True,
            'smtp_server': 'smtp.gmail.com',
            'recipient_emails': ['admin@company.com']
        },
        'slack': {
            'enabled': True,
            'webhook_url': 'https://hooks.slack.com/...'
        }
    }
})

# Auto alerts on issues
alert_manager.alert_on_drift(drift_results)
alert_manager.alert_on_fairness_violation(fairness_results)
alert_manager.alert_on_bias(bias_report)
alert_manager.alert_on_adversarial_attack(attack_results)
```

**Channels:**
- Console
- Email (SMTP)
- Slack
- Webhook
- SMS (Twilio)

---

### 5. **Framework Adapters** ğŸ”Œ

Support cho multiple ML frameworks:

```python
from core.adapters import SklearnAdapter, PyTorchAdapter, TensorFlowAdapter

# Sklearn
sklearn_adapter = SklearnAdapter(RandomForestClassifier())

# PyTorch
pytorch_model = MyNeuralNetwork()
pytorch_adapter = PyTorchAdapter(
    pytorch_model, 
    loss_fn=nn.CrossEntropyLoss(),
    optimizer=torch.optim.Adam(pytorch_model.parameters())
)

# TensorFlow
tf_model = tf.keras.Sequential([...])
tf_adapter = TensorFlowAdapter(tf_model)

# Use nhÆ° nhau
responsible_model = ResponsibleModelWrapper(adapter.model, rai)
```

---

### 6. **Drift Detection** ğŸ“Š

Comprehensive drift monitoring:

```python
from monitoring.drift_detector import DriftDetector

detector = DriftDetector(threshold=0.05)
detector.set_reference(X_train, y_train, predictions=train_preds)

# Detect all types of drift
drift_results = detector.detect_all_drifts(
    X_new, y_new, predictions_new, model
)

# PSI (Population Stability Index)
psi_scores = detector.monitor_features_psi(X_new)
```

**Drift Types:**
- Data Drift (Kolmogorov-Smirnov test)
- Prediction Drift
- Concept Drift
- PSI monitoring

---

## ğŸ“š Advanced Usage

### Complete Pipeline Example

```python
# 1. Setup
rai = ResponsibleAI()
alert_manager = AlertManager(config)
audit_logger = AuditLogger(handlers=[...])
mitigation_engine = MitigationEngine(rai)

# 2. Data preparation & mitigation
X_clean, y_clean, _ = mitigation_engine.analyze_and_mitigate_bias(
    X_train, y_train, sensitive_features
)

# 3. Model training
model = RandomForestClassifier()
responsible_model = ResponsibleModelWrapper(model, rai)
responsible_model.fit(X_clean, y_clean)

# 4. Robustness testing
attack_gen = AttackGenerator(model)
robustness = attack_gen.evaluate_robustness(X_test, y_test)
alert_manager.alert_on_adversarial_attack(robustness)

# 5. Adversarial training if needed
if robustness['overall_robustness_score'] < 0.7:
    defense = DefenseTrainer(model, attack_gen)
    defense.adversarial_training(X_train, y_train)

# 6. Deployment monitoring
drift_detector = DriftDetector()
drift_detector.set_reference(X_train, predictions=model.predict(X_train))

# In production
drift = drift_detector.detect_all_drifts(X_production, ...)
if drift['overall_drift_detected']:
    alert_manager.alert_on_drift(drift)
    # Trigger retraining pipeline
```

---

## ğŸ¬ Examples

### Basic Demo
```bash
python examples/demo.py
```

### Advanced Demo (All Features)
```bash
python examples/advanced_demo.py
```

---

## ğŸ“Š Research Papers & References

Framework nÃ y triá»ƒn khai cÃ¡c ká»¹ thuáº­t tá»«:

1. **Fairness:**
   - Hardt et al. "Equality of Opportunity in Supervised Learning" (2016)
   - Feldman et al. "Certifying and Removing Disparate Impact" (2015)

2. **Adversarial Robustness:**
   - Goodfellow et al. "Explaining and Harnessing Adversarial Examples" (2015) - FGSM
   - Madry et al. "Towards Deep Learning Models Resistant to Adversarial Attacks" (2018) - PGD

3. **Privacy:**
   - Dwork et al. "Differential Privacy" (2006)
   - Abadi et al. "Deep Learning with Differential Privacy" (2016) - DP-SGD

4. **Explainability:**
   - Lundberg & Lee "A Unified Approach to Interpreting Model Predictions" (2017) - SHAP
   - Ribeiro et al. "Why Should I Trust You?" (2016) - LIME

---

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:
- Causal explainability module
- DP-SGD implementation
- More attack methods
- Additional fairness metrics

---

## ğŸ“„ License

MIT License - see LICENSE file

---

## ğŸ‘¥ Authors

**EAI-RAIDS Team**
- Advanced Responsible AI Research

---

## ğŸŒŸ Citation

If you use this framework in your research, please cite:

```bibtex
@software{eai_raids_2025,
  title={EAI-RAIDS: Enterprise Responsible AI Framework},
  author={EAI-RAIDS Team},
  year={2025},
  url={https://github.com/Hoangnhat2711/EAI-RAIDSs}
}
```

---

## ğŸ“ Support

- ğŸ› Issues: [GitHub Issues](https://github.com/Hoangnhat2711/EAI-RAIDSs/issues)
- ğŸ“§ Email: support@eai-raids.com
- ğŸ“– Docs: [Documentation](https://eai-raids.readthedocs.io)

---

**â­ If you find this useful, please star the repository!**
